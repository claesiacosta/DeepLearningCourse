{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Autograd (automatic differentiation) is the pytorch module that performs gradient tracking and computation\n",
    "# By default, when tensors are created their gradients is not tracked\n",
    "x = torch.ones(1, 10)\n",
    "print(x.requires_grad)\n",
    "\n",
    "# You can change it using the requires_grad_() function\n",
    "x.requires_grad_()\n",
    "print(x.requires_grad)\n",
    "\n",
    "# Alternatively, when creating a tensor, you can directly set 'requires_grad=True'\n",
    "x = torch.ones(1, 10, requires_grad=True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f45acad7ba8>\n",
      "<MulBackward0 object at 0x7f467c251470>\n",
      "<MeanBackward0 object at 0x7f467c251470>\n"
     ]
    }
   ],
   "source": [
    "# If you create a tensor y from x as the result of an operation, it will have a gradient function (grad_fn) which is specific to this operation\n",
    "y = x + 50\n",
    "print(y.grad_fn)\n",
    "\n",
    "y = x * 50\n",
    "print(y.grad_fn)\n",
    "\n",
    "y = x.mean()\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claesia/.local/lib/python3.6/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    }
   ],
   "source": [
    "# Backward: computes the gradients \n",
    "x = torch.ones(1, 10, requires_grad=True)\n",
    "y = x.mean()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Sometimes (for instance at testing), you don't need to keep tracking of the gradients for some operations\n",
    "# Then, in order to save memory you can simply deactivate gradient tracking\n",
    "y = x.mean()\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x.mean()\n",
    "    print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: define a simple operation Y=W*X+B (with X=1, W=2 and B=3)\n",
    "# Compute and print the gradients of X, W and B\n",
    "X = torch.tensor(1.0, requires_grad=True)\n",
    "W = torch.tensor(2.0, requires_grad=True)\n",
    "B = torch.tensor(3.0, requires_grad=True)\n",
    "Y = W*X+B\n",
    "Y.backward()\n",
    "print(X.grad)\n",
    "print(W.grad)\n",
    "print(B.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  256\n",
      "Output size:  2\n",
      "Parameter containing:\n",
      "tensor([-0.0279, -0.0232], requires_grad=True)\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example of creating a simple network, computing the output and the gradients\n",
    "\n",
    "# Define the network (one linear layer and a nonlinearity)\n",
    "linear_layer = nn.Linear(256, 2)\n",
    "activation_fn = nn.Sigmoid()\n",
    "print('Input size: ', linear_layer.in_features)\n",
    "print('Output size: ', linear_layer.out_features)\n",
    "print(linear_layer.bias)\n",
    "print(linear_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Create an image-like input and an arbitrary output\n",
    "input_image = torch.randn(16,16)\n",
    "plt.imshow(input_image.numpy())\n",
    "plt.show()\n",
    "\n",
    "output_true = torch.tensor([0, 1], dtype=torch.float)\n",
    "print(output_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4304, 0.4524], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "input_reshape = input_image.reshape(256) # vectorize the input image\n",
    "output_predicted = activation_fn(linear_layer(input_reshape))\n",
    "print(output_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779987812042236\n",
      "Weight gradient:  tensor([[ 0.0885, -0.1278, -0.0305, -0.0732,  0.1597, -0.1300, -0.2822, -0.2460,\n",
      "          0.0445, -0.0788,  0.0152, -0.1085,  0.1295, -0.0176, -0.1400, -0.0520,\n",
      "         -0.1086,  0.3367, -0.0091, -0.0473,  0.2723,  0.2367, -0.4065,  0.2305,\n",
      "         -0.3014,  0.0548, -0.2234, -0.1533, -0.1546, -0.5120, -0.0531,  0.1999,\n",
      "          0.1135, -0.0754,  0.2271, -0.1550,  0.1021, -0.1378, -0.0245,  0.3683,\n",
      "          0.2308,  0.4419, -0.2801,  0.2730, -0.0179, -0.2432, -0.0216,  0.1033,\n",
      "         -0.0015, -0.1080, -0.2376, -0.2375,  0.3810,  0.0369,  0.1134,  0.2952,\n",
      "         -0.0441, -0.2768, -0.2434, -0.0716, -0.0300,  0.1023,  0.1207, -0.0487,\n",
      "         -0.3626, -0.3222,  0.0369,  0.0478,  0.2344,  0.1412,  0.2328,  0.0494,\n",
      "         -0.0202,  0.0152, -0.3819,  0.4731,  0.2088, -0.2133, -0.1032,  0.2511,\n",
      "         -0.4834, -0.0913,  0.2355,  0.1249,  0.0039,  0.1499,  0.0317, -0.0488,\n",
      "          0.0678,  0.3935,  0.1404, -0.0622,  0.0641,  0.0823,  0.2014, -0.0345,\n",
      "         -0.2858, -0.3215, -0.2034, -0.1830,  0.0718, -0.0233, -0.1581, -0.1114,\n",
      "          0.1700,  0.0074,  0.1692,  0.2373, -0.1544, -0.0460, -0.2707,  0.2446,\n",
      "         -0.0198, -0.1660, -0.0314,  0.2431, -0.2287, -0.3367, -0.0300, -0.2012,\n",
      "         -0.1787, -0.0650, -0.1894, -0.1151, -0.1920, -0.3676,  0.1206,  0.0924,\n",
      "          0.0124, -0.1505,  0.5205, -0.2640, -0.4373,  0.2225, -0.1540, -0.1958,\n",
      "          0.2415, -0.0082,  0.1888,  0.0663,  0.2753,  0.0664, -0.0622, -0.2262,\n",
      "          0.2399, -0.0925, -0.0450,  0.0610,  0.0517, -0.2083,  0.0284, -0.0934,\n",
      "         -0.0900,  0.1035,  0.0057,  0.2275,  0.2789, -0.3535, -0.0926,  0.4510,\n",
      "         -0.0368,  0.2481,  0.0074, -0.0628, -0.0664, -0.0428, -0.3888,  0.0748,\n",
      "          0.1749, -0.1621,  0.3816,  0.1587, -0.0830,  0.3726,  0.2618, -0.0424,\n",
      "         -0.2425, -0.2392,  0.2405,  0.1708, -0.1414, -0.2155, -0.0735,  0.1015,\n",
      "          0.0396, -0.0636, -0.1224,  0.1076,  0.1473,  0.1004,  0.1627, -0.0230,\n",
      "         -0.0997,  0.2400,  0.0640, -0.1493,  0.0899, -0.1422,  0.1871, -0.1586,\n",
      "         -0.2116,  0.2443, -0.0565,  0.1500, -0.1565,  0.2626,  0.0852,  0.4436,\n",
      "          0.1396,  0.1824,  0.3965,  0.0165, -0.2233, -0.1386,  0.0189, -0.1186,\n",
      "         -0.0665,  0.0911, -0.0999,  0.0793,  0.0200, -0.2506,  0.1210,  0.1313,\n",
      "          0.1562,  0.1255,  0.0110,  0.0877, -0.0892, -0.2850,  0.2440,  0.1431,\n",
      "          0.0341,  0.1824,  0.0234, -0.0914,  0.0061,  0.1976,  0.0332,  0.1558,\n",
      "          0.2124, -0.0269, -0.0379, -0.3846, -0.1198,  0.2313,  0.1597, -0.2950,\n",
      "         -0.0496,  0.5537,  0.0092, -0.0512,  0.0114,  0.1485,  0.1669, -0.1582],\n",
      "        [-0.1126,  0.1626,  0.0388,  0.0931, -0.2033,  0.1654,  0.3590,  0.3130,\n",
      "         -0.0566,  0.1003, -0.0193,  0.1380, -0.1647,  0.0224,  0.1782,  0.0661,\n",
      "          0.1382, -0.4284,  0.0116,  0.0602, -0.3465, -0.3012,  0.5172, -0.2933,\n",
      "          0.3835, -0.0698,  0.2843,  0.1951,  0.1967,  0.6515,  0.0675, -0.2543,\n",
      "         -0.1445,  0.0959, -0.2890,  0.1972, -0.1300,  0.1754,  0.0312, -0.4687,\n",
      "         -0.2936, -0.5623,  0.3564, -0.3474,  0.0228,  0.3094,  0.0275, -0.1314,\n",
      "          0.0019,  0.1375,  0.3023,  0.3022, -0.4848, -0.0470, -0.1443, -0.3756,\n",
      "          0.0561,  0.3522,  0.3098,  0.0911,  0.0381, -0.1302, -0.1536,  0.0620,\n",
      "          0.4615,  0.4099, -0.0470, -0.0608, -0.2983, -0.1797, -0.2962, -0.0629,\n",
      "          0.0257, -0.0194,  0.4860, -0.6020, -0.2658,  0.2715,  0.1314, -0.3195,\n",
      "          0.6152,  0.1162, -0.2996, -0.1589, -0.0050, -0.1908, -0.0404,  0.0621,\n",
      "         -0.0863, -0.5008, -0.1787,  0.0792, -0.0816, -0.1047, -0.2563,  0.0439,\n",
      "          0.3637,  0.4091,  0.2589,  0.2329, -0.0913,  0.0297,  0.2011,  0.1417,\n",
      "         -0.2163, -0.0094, -0.2153, -0.3020,  0.1965,  0.0586,  0.3445, -0.3112,\n",
      "          0.0252,  0.2112,  0.0399, -0.3093,  0.2910,  0.4284,  0.0382,  0.2560,\n",
      "          0.2273,  0.0827,  0.2410,  0.1465,  0.2443,  0.4678, -0.1534, -0.1176,\n",
      "         -0.0158,  0.1916, -0.6623,  0.3360,  0.5564, -0.2831,  0.1959,  0.2491,\n",
      "         -0.3073,  0.0105, -0.2402, -0.0843, -0.3504, -0.0845,  0.0792,  0.2878,\n",
      "         -0.3053,  0.1177,  0.0573, -0.0777, -0.0657,  0.2650, -0.0361,  0.1189,\n",
      "          0.1145, -0.1317, -0.0073, -0.2895, -0.3548,  0.4498,  0.1179, -0.5739,\n",
      "          0.0468, -0.3157, -0.0095,  0.0799,  0.0845,  0.0545,  0.4948, -0.0952,\n",
      "         -0.2226,  0.2062, -0.4855, -0.2019,  0.1056, -0.4742, -0.3332,  0.0540,\n",
      "          0.3086,  0.3043, -0.3060, -0.2173,  0.1799,  0.2742,  0.0935, -0.1292,\n",
      "         -0.0504,  0.0810,  0.1557, -0.1369, -0.1874, -0.1277, -0.2070,  0.0293,\n",
      "          0.1268, -0.3054, -0.0814,  0.1900, -0.1144,  0.1809, -0.2381,  0.2018,\n",
      "          0.2692, -0.3109,  0.0719, -0.1908,  0.1991, -0.3341, -0.1084, -0.5645,\n",
      "         -0.1777, -0.2321, -0.5045, -0.0211,  0.2841,  0.1764, -0.0241,  0.1509,\n",
      "          0.0847, -0.1159,  0.1271, -0.1010, -0.0254,  0.3189, -0.1540, -0.1671,\n",
      "         -0.1988, -0.1597, -0.0140, -0.1115,  0.1135,  0.3627, -0.3105, -0.1821,\n",
      "         -0.0434, -0.2321, -0.0298,  0.1163, -0.0077, -0.2514, -0.0423, -0.1983,\n",
      "         -0.2703,  0.0343,  0.0482,  0.4894,  0.1525, -0.2943, -0.2032,  0.3754,\n",
      "          0.0631, -0.7045, -0.0118,  0.0652, -0.0145, -0.1889, -0.2124,  0.2014]])\n",
      "Biases gradient:  tensor([ 0.2152, -0.2738])\n"
     ]
    }
   ],
   "source": [
    "# Now, we need to define a loss function to measure the difference between the 'true' and 'predicted' output\n",
    "# This loss function will be use to compute the gradients and update the network parameters\n",
    "\n",
    "# Use the binary cross entropy loss function\n",
    "loss_fn = nn.BCELoss() \n",
    "\n",
    "# calculate the loss with the given values (true and predicted)\n",
    "loss = loss_fn(output_predicted, output_true)\n",
    "\n",
    "# You can print the loss value (or store it, which is useful for monitoring the training) how far away is from the true value\n",
    "print(loss.item())\n",
    "\n",
    "# Compute the gradients\n",
    "loss.backward()\n",
    "\n",
    "print ('Weight gradient: ', linear_layer.weight.grad)\n",
    "print ('Biases gradient: ', linear_layer.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update the network parameters, we need to use an 'optimizer': it basically defines which optimization algorithm is used\n",
    "\n",
    "# Let's use the stochastic gradient algorithm\n",
    "optimizer = torch.optim.SGD(linear_layer.parameters(), lr=0.01)\n",
    "\n",
    "# and apply it to update the parameters\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0301, -0.0204], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Save and load the linear layer of the model\n",
    "torch.save(linear_layer, 'fnn_model.pt')\n",
    "model = torch.load('fnn_model.pt')\n",
    "model\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0301, -0.0204], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Save and load only the model's parameters (recommended)\n",
    "torch.save(linear_layer.state_dict(), 'fnn_model_params.pt')\n",
    "model = nn.Linear(256, 2) #need to first instanciate the model\n",
    "model.load_state_dict(torch.load('fnn_model_params.pt')) #now load its parameters\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
